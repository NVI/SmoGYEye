{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, clear outputs (Cell > All Output > Clear) before committing to Git\n",
    "# There might be a better way\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "cnx = sqlite3.connect('FPA_FOD_20170508.sqlite')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import tree, preprocessing\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT FIRE_YEAR,DISCOVERY_TIME,STAT_CAUSE_DESCR,CONT_DATE,CONT_TIME,LATITUDE,LONGITUDE,STATE,DISCOVERY_DATE,FIRE_SIZE,FIRE_SIZE_CLASS FROM 'Fires'\", cnx)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DISCOVERY_DATE'] = pd.to_datetime(df['DISCOVERY_DATE'] - pd.Timestamp(0).to_julian_date(), unit='D')\n",
    "df['CONT_DATE'] = pd.to_datetime(df['CONT_DATE'] - pd.Timestamp(0).to_julian_date(), unit='D')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DISCOVERY_MONTH'] = pd.DatetimeIndex(df['DISCOVERY_DATE']).month\n",
    "df['DISCOVERY_DAY'] = pd.DatetimeIndex(df['DISCOVERY_DATE']).day\n",
    "df['DISCOVERY_DAY_OF_WEEK'] = df['DISCOVERY_DATE'].dt.weekday_name\n",
    "\n",
    "#df['CONT_DATE'].fillna(0)\n",
    "df['CONT_MONTH'] = pd.DatetimeIndex(df['CONT_DATE']).month\n",
    "df['CONT_DAY'] = pd.DatetimeIndex(df['CONT_DATE']).day\n",
    "df['CONT_DAY_OF_WEEK'] = df['CONT_DATE'].dt.weekday_name\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df['STAT_CAUSE_DESCR'] = le.fit_transform(df['STAT_CAUSE_DESCR'])\n",
    "df['STATE'] = le.fit_transform(df['STATE'])\n",
    "df['DISCOVERY_DAY_OF_WEEK'] = le.fit_transform(df['DISCOVERY_DAY_OF_WEEK'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['CONT_DAY_OF_WEEK']=df['CONT_DAY_OF_WEEK'].fillna(\"Unknown\")\n",
    "df['CONT_DAY']=df['CONT_DAY'].fillna(\"0\")\n",
    "df['CONT_MONTH']=df['CONT_MONTH'].fillna(\"0\")\n",
    "df['CONT_TIME']=df['CONT_TIME'].fillna(\"0\")\n",
    "df['DISCOVERY_TIME']=df['DISCOVERY_TIME'].fillna(\"0\")\n",
    "\n",
    "df['CONT_DAY_OF_WEEK'] = le.fit_transform(df['CONT_DAY_OF_WEEK'])\n",
    "df['FIRE_SIZE_CLASS'] = le.fit_transform(df['FIRE_SIZE_CLASS'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CONT_MONTH']=df['CONT_MONTH'].astype('Float64')\n",
    "df['CONT_DAY']=df['CONT_DAY'].astype('Float64')\n",
    "#df['CONT_TIME']=df['CONT_TIME'].astype('Float64')\n",
    "#df['DISCOVERY_DATE']=df['DISCOVERY_DATE'].astype('Float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df:\n",
    "    print(item)\n",
    "    print(df[item].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=df['FIRE_SIZE_CLASS']\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=df.drop(['FIRE_SIZE','FIRE_SIZE_CLASS','DISCOVERY_DATE','CONT_DATE','STATE','CONT_TIME','DISCOVERY_TIME'],axis=1)\n",
    "logits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(logits,labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg.predict(x_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.activations import relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cat=keras.utils.to_categorical(labels,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(logits,labels_cat,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(BatchNormalization(input_shape=[10]))\n",
    "model.add(Dense(500,kernel_initializer='truncated_normal'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(300,kernel_initializer='truncated_normal'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(7,kernel_initializer='truncated_normal'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=0.01, momentum=0.9,decay=1e-6),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=10,validation_data=(np.array(x_test),np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main focus:\n",
    "Write the algorithm, who joins the wildfire data with the airquality data over the closest latitude and longitude and the closest date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRE_YEAR\n",
      "Date\n",
      "FIRE_YEAR\n",
      "AQI\n",
      "FIRE_YEAR\n",
      "Category\n",
      "FIRE_YEAR\n",
      "Defining Parameter\n",
      "FIRE_YEAR\n",
      "Defining Site\n",
      "FIRE_YEAR\n",
      "Latitude\n",
      "FIRE_YEAR\n",
      "Longitude\n",
      "DISCOVERY_TIME\n",
      "Date\n",
      "DISCOVERY_TIME\n",
      "AQI\n",
      "DISCOVERY_TIME\n",
      "Category\n",
      "DISCOVERY_TIME\n",
      "Defining Parameter\n",
      "DISCOVERY_TIME\n",
      "Defining Site\n",
      "DISCOVERY_TIME\n",
      "Latitude\n",
      "DISCOVERY_TIME\n",
      "Longitude\n",
      "STAT_CAUSE_DESCR\n",
      "Date\n",
      "STAT_CAUSE_DESCR\n",
      "AQI\n",
      "STAT_CAUSE_DESCR\n",
      "Category\n",
      "STAT_CAUSE_DESCR\n",
      "Defining Parameter\n",
      "STAT_CAUSE_DESCR\n",
      "Defining Site\n",
      "STAT_CAUSE_DESCR\n",
      "Latitude\n",
      "STAT_CAUSE_DESCR\n",
      "Longitude\n",
      "CONT_DATE\n",
      "Date\n",
      "CONT_DATE\n",
      "AQI\n",
      "CONT_DATE\n",
      "Category\n",
      "CONT_DATE\n",
      "Defining Parameter\n",
      "CONT_DATE\n",
      "Defining Site\n",
      "CONT_DATE\n",
      "Latitude\n",
      "CONT_DATE\n",
      "Longitude\n",
      "CONT_TIME\n",
      "Date\n",
      "CONT_TIME\n",
      "AQI\n",
      "CONT_TIME\n",
      "Category\n",
      "CONT_TIME\n",
      "Defining Parameter\n",
      "CONT_TIME\n",
      "Defining Site\n",
      "CONT_TIME\n",
      "Latitude\n",
      "CONT_TIME\n",
      "Longitude\n",
      "LATITUDE\n",
      "Date\n",
      "LATITUDE\n",
      "AQI\n",
      "LATITUDE\n",
      "Category\n",
      "LATITUDE\n",
      "Defining Parameter\n",
      "LATITUDE\n",
      "Defining Site\n",
      "LATITUDE\n",
      "Latitude\n",
      "LATITUDE\n",
      "Longitude\n",
      "LONGITUDE\n",
      "Date\n",
      "LONGITUDE\n",
      "AQI\n",
      "LONGITUDE\n",
      "Category\n",
      "LONGITUDE\n",
      "Defining Parameter\n",
      "LONGITUDE\n",
      "Defining Site\n",
      "LONGITUDE\n",
      "Latitude\n",
      "LONGITUDE\n",
      "Longitude\n",
      "STATE\n",
      "Date\n",
      "STATE\n",
      "AQI\n",
      "STATE\n",
      "Category\n",
      "STATE\n",
      "Defining Parameter\n",
      "STATE\n",
      "Defining Site\n",
      "STATE\n",
      "Latitude\n",
      "STATE\n",
      "Longitude\n",
      "DISCOVERY_DATE\n",
      "Date\n",
      "DISCOVERY_DATE\n",
      "AQI\n",
      "DISCOVERY_DATE\n",
      "Category\n",
      "DISCOVERY_DATE\n",
      "Defining Parameter\n",
      "DISCOVERY_DATE\n",
      "Defining Site\n",
      "DISCOVERY_DATE\n",
      "Latitude\n",
      "DISCOVERY_DATE\n",
      "Longitude\n",
      "FIRE_SIZE\n",
      "Date\n",
      "FIRE_SIZE\n",
      "AQI\n",
      "FIRE_SIZE\n",
      "Category\n",
      "FIRE_SIZE\n",
      "Defining Parameter\n",
      "FIRE_SIZE\n",
      "Defining Site\n",
      "FIRE_SIZE\n",
      "Latitude\n",
      "FIRE_SIZE\n",
      "Longitude\n",
      "FIRE_SIZE_CLASS\n",
      "Date\n",
      "FIRE_SIZE_CLASS\n",
      "AQI\n",
      "FIRE_SIZE_CLASS\n",
      "Category\n",
      "FIRE_SIZE_CLASS\n",
      "Defining Parameter\n",
      "FIRE_SIZE_CLASS\n",
      "Defining Site\n",
      "FIRE_SIZE_CLASS\n",
      "Latitude\n",
      "FIRE_SIZE_CLASS\n",
      "Longitude\n",
      "DISCOVERY_MONTH\n",
      "Date\n",
      "DISCOVERY_MONTH\n",
      "AQI\n",
      "DISCOVERY_MONTH\n",
      "Category\n",
      "DISCOVERY_MONTH\n",
      "Defining Parameter\n",
      "DISCOVERY_MONTH\n",
      "Defining Site\n",
      "DISCOVERY_MONTH\n",
      "Latitude\n",
      "DISCOVERY_MONTH\n",
      "Longitude\n",
      "DISCOVERY_DAY\n",
      "Date\n",
      "DISCOVERY_DAY\n",
      "AQI\n",
      "DISCOVERY_DAY\n",
      "Category\n",
      "DISCOVERY_DAY\n",
      "Defining Parameter\n",
      "DISCOVERY_DAY\n",
      "Defining Site\n",
      "DISCOVERY_DAY\n",
      "Latitude\n",
      "DISCOVERY_DAY\n",
      "Longitude\n",
      "DISCOVERY_DAY_OF_WEEK\n",
      "Date\n",
      "DISCOVERY_DAY_OF_WEEK\n",
      "AQI\n",
      "DISCOVERY_DAY_OF_WEEK\n",
      "Category\n",
      "DISCOVERY_DAY_OF_WEEK\n",
      "Defining Parameter\n",
      "DISCOVERY_DAY_OF_WEEK\n",
      "Defining Site\n",
      "DISCOVERY_DAY_OF_WEEK\n",
      "Latitude\n",
      "DISCOVERY_DAY_OF_WEEK\n",
      "Longitude\n",
      "CONT_MONTH\n",
      "Date\n",
      "CONT_MONTH\n",
      "AQI\n",
      "CONT_MONTH\n",
      "Category\n",
      "CONT_MONTH\n",
      "Defining Parameter\n",
      "CONT_MONTH\n",
      "Defining Site\n",
      "CONT_MONTH\n",
      "Latitude\n",
      "CONT_MONTH\n",
      "Longitude\n",
      "CONT_DAY\n",
      "Date\n",
      "CONT_DAY\n",
      "AQI\n",
      "CONT_DAY\n",
      "Category\n",
      "CONT_DAY\n",
      "Defining Parameter\n",
      "CONT_DAY\n",
      "Defining Site\n",
      "CONT_DAY\n",
      "Latitude\n",
      "CONT_DAY\n",
      "Longitude\n",
      "CONT_DAY_OF_WEEK\n",
      "Date\n",
      "CONT_DAY_OF_WEEK\n",
      "AQI\n",
      "CONT_DAY_OF_WEEK\n",
      "Category\n",
      "CONT_DAY_OF_WEEK\n",
      "Defining Parameter\n",
      "CONT_DAY_OF_WEEK\n",
      "Defining Site\n",
      "CONT_DAY_OF_WEEK\n",
      "Latitude\n",
      "CONT_DAY_OF_WEEK\n",
      "Longitude\n"
     ]
    }
   ],
   "source": [
    "for line in df:\n",
    "    MinDistance=10000000000000\n",
    "    MinDistanceCloumn=None\n",
    "    #print(line)\n",
    "    for line2 in aqi: \n",
    "        print(line)\n",
    "        print(line2)\n",
    "        #Distance = (line['LATITUDE']-line2['LATITUDE'])^2 + (line['LONGITUDE']-line2['LONGITUDE'])^2\n",
    "        #if Distance < MinDistance:\n",
    "         #   MinDistance=Distance\n",
    "          #  MinDistanceColumn=line2\n",
    "    #a = line2.drop['LATITUDE','LONGITUDE']   #drop longitude,latitude from air_quality[line2.index]\n",
    "    #s=pd.Series()    #join line and a    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_site_list(site_file):\n",
    "    # Make sure that state, county, and site codes are read as strings\n",
    "    # instead of numbers\n",
    "    col_types = {'State Code': str, 'County Code': str, 'Site Number': str}\n",
    "\n",
    "    sites = pd.read_csv(site_file, dtype=col_types)\n",
    "\n",
    "    # Columns that can be dropped from the site listing\n",
    "    cols_to_drop = [\n",
    "        'Land Use', 'Location Setting', 'Met Site State Code',\n",
    "        'Met Site County Code', 'Met Site Site Number', 'Met Site Type',\n",
    "        'Met Site Distance', 'Met Site Direction', 'GMT Offset',\n",
    "        'Owning Agency', 'Local Site Name', \"Address\", \"Zip Code\",\n",
    "        \"State Name\", \"County Name\", \"City Name\", \"CBSA Name\", \"Tribe Name\",\n",
    "        \"Extraction Date\"\n",
    "    ]\n",
    "\n",
    "    sites = sites.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Convert site closing dates to datetime64 objects (does not work\n",
    "    # with read_csv())\n",
    "    sites['Site Closed Date'] = pd.to_datetime(sites['Site Closed Date'])\n",
    "\n",
    "    # Get sites that have been closed down before 1992 and drop them\n",
    "    # from the list\n",
    "    outdated = sites.loc[\n",
    "        sites['Site Closed Date'] < pd.to_datetime('01-01-1992')]\n",
    "    sites = sites.drop(outdated.index)\n",
    "\n",
    "    # Get the complete site code, add it as a column, and finally\n",
    "    # use the site code as the index\n",
    "    sites['site-code'] = sites['State Code'] + '-' + sites[\n",
    "        'County Code'] + '-' + sites['Site Number']\n",
    "    sites = sites.set_index('site-code')\n",
    "\n",
    "    # Divide the data into two Series: one with latitude coordinates and one\n",
    "    # with longitude coordinates\n",
    "    sites_lat = sites['Latitude']\n",
    "    sites_lon = sites['Longitude']\n",
    "\n",
    "    # Transform the site listings into a dictionary where keys are site\n",
    "    # codes and values are coordinates}\n",
    "    sites_lat = sites_lat.to_dict()\n",
    "    sites_lon = sites_lon.to_dict()\n",
    "\n",
    "    # Return the two dictionaries with the coordinates\n",
    "    return sites_lat, sites_lon\n",
    "\n",
    "\n",
    "def preprocess_aqi(site_file, aqi_file):\n",
    "    # Read daily AQI measurements from year XXXX\n",
    "    aqi = pd.read_csv(aqi_file)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    cols_to_drop = [\n",
    "        'State Name', 'State Code', 'county Name', 'County Code',\n",
    "        'Number of Sites Reporting'\n",
    "    ]\n",
    "    aqi.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    # Get coordinate information for measurement sites\n",
    "    lat_coords, lon_coords = preprocess_site_list(site_file)\n",
    "\n",
    "    # Add column containing the site information (including location\n",
    "    # coordinates) to each AQI measurement\n",
    "    aqi['Latitude'] = aqi['Defining Site'].map(lat_coords)\n",
    "    aqi['Longitude'] = aqi['Defining Site'].map(lon_coords)\n",
    "\n",
    "    return aqi\n",
    "\n",
    "\n",
    "\n",
    "aqi = preprocess_aqi('aqs_sites.csv', 'daily_aqi_by_county_2015.csv')\n",
    "print(aqi.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_aqi(\"aqs_sites.csv\",\"daily_aqi_by_county_2015.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBModel()\n",
    "\n",
    "clf.fit(x_train, y_train,\n",
    "        eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "        eval_metric='logloss',\n",
    "        verbose=True)\n",
    "\n",
    "ypred = clf.predict(x_test)\n",
    "print(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STAT_CAUSE_DESCR'].value_counts().plot(kind='barh',color='coral')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arson = df[df['STAT_CAUSE_DESCR']=='Arson']\n",
    "df_arson['DAY_OF_WEEK'].value_counts().plot(kind='barh',color='coral')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df,size=10):\n",
    "    corr = df.corr()  #the default method is pearson\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(corr,cmap=plt.cm.Oranges)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "plot_corr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='scatter',x='LONGITUDE',y='LATITUDE',color='coral',alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lightning = df[df['STAT_CAUSE_DESCR']=='Lightning']\n",
    "df_lightning['DAY_OF_WEEK'].value_counts().plot(kind='barh',color='coral')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DAY_OF_WEEK'].value_counts().plot(kind='barh',color='coral')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STATE'].value_counts().head(n=10).plot(kind='barh',color='coral')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CA = df[df['STATE']=='CA']\n",
    "df_CA['STAT_CAUSE_DESCR'].value_counts().plot(kind='barh',color='coral',title='causes of fires for CA')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
